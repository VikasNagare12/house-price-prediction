{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Value Analysis\n",
    "\n",
    "I want to focus on the target variable which is SalePrice. Let's create a histogram to see if the target variable is Normally distributed. If we want to create any linear model, it is essential that the features are normally distributed. This is one of the assumptions of multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrogram to see how data is distributes\n",
    "sns.set_context(\"paper\", rc={\"font.size\":8,\"axes.titlesize\":8,\"axes.labelsize\":5}) \n",
    "sns.distplot(train_df['SalePrice'],fit=norm)\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train_df['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "## Plotting the box plot. \n",
    "sns.boxplot(train_df['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three charts above can tell us a lot about our target variable.\n",
    "\n",
    "- Our target variable, SalePrice is not normally distributed.\n",
    "- Our target variable is right-skewed.\n",
    "- There are multiple outliers in the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: \" + str(train_df['SalePrice'].skew()))\n",
    "print(\"Kurtosis: \" + str(train_df['SalePrice'].kurt()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view correlation between train_df features and sales price\n",
    "sns.set(font_scale=3)\n",
    "plt.figure(figsize=(50,35))\n",
    "sns.heatmap(train_df.corr(),annot=True,annot_kws={'size':30},fmt='.1f',\n",
    "           cmap='PiYG',linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the correlation of all the features with target variable. \n",
    "sns.set(font_scale=1)\n",
    "corr_new_train=train_df.corr()\n",
    "plt.figure(figsize=(5,15))\n",
    "sns.heatmap(corr_new_train[['SalePrice']].sort_values(by=['SalePrice'],ascending=False).head(30),annot_kws={\"size\": 16},vmin=-1, cmap='PiYG', annot=True)\n",
    "\n",
    "#(train_df.corr()**2)[\"SalePrice\"].sort_values(ascending = False)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(40, 2,figsize=(15,300))\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "for i,ax in zip(all_data_df.columns,axes.flatten()):\n",
    "    sns.scatterplot(x=train_df[i], y=train_df[\"SalePrice\"],ax=ax)\n",
    "    plt.xlabel(i,fontsize=16)\n",
    "    plt.ylabel('SalePrice',fontsize=16)\n",
    "    ax.set_yticks(np.arange(0,900001,100000))\n",
    "    ax.set_title('SalePrice'+' - '+str(i),color=color,fontweight='bold',size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagorical_mode=[]\n",
    "catagorical_ordinal=[]\n",
    "catagorical_nominal=[]\n",
    "numrical=[]\n",
    "numrical_mean=[]\n",
    "numrical_median=[]\n",
    "qual_count=all_data_df.OverallQual.value_counts().sort_index()\n",
    "len(qual_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, if the assumptions are met, the residuals will be randomly scattered around the centerline of zero with no apparent pattern. The residual will look like an unstructured cloud of points centered around zero. However, our residual plot is anything but an unstructured cloud of points. Even though it seems like there is a linear relationship between the response variable and predictor variable, the residual plot looks more like a funnel. The error plot shows that as GrLivArea value increases, the variance also increases, which is the characteristics known as Heteroscedasticity. Let's break this down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trainsforming target variable using numpy.log1p, \n",
    "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histrogram to see how data is distributes\n",
    "sns.set_context(\"paper\", rc={\"font.size\":8,\"axes.titlesize\":8,\"axes.labelsize\":5}) \n",
    "sns.distplot(train_df['SalePrice'],fit=norm)\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train_df['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "## Plotting the box plot. \n",
    "sns.boxplot(train_df['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make sure that the target variable follows a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a comparison of the pre-transformed and post-transformed state of residual plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.residplot(x = train_df.GrLivArea, y = train_df.SalePrice);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the pre-transformed chart on the left has heteroscedasticity, and the post-transformed chart on the right has Homoscedasticity(almost an equal amount of variance across the zero lines). It looks like a blob of data points and doesn't seem to give away any relationships. That's the sort of relationship we would like to see to avoid some of these assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some missing values are intentionally left blank, for example: In the Alley feature \n",
    "## there are blank values meaning that there are no alley's in that specific house. \n",
    "missing_val_col = [\"Alley\", \n",
    "                   \"PoolQC\", \n",
    "                   \"MiscFeature\",\n",
    "                   \"Fence\",\n",
    "                   \"FireplaceQu\",\n",
    "                   \"GarageType\",\n",
    "                   \"GarageFinish\",\n",
    "                   \"GarageQual\",\n",
    "                   \"GarageCond\",\n",
    "                   'BsmtQual',\n",
    "                   'BsmtCond',\n",
    "                   'BsmtExposure',\n",
    "                   'BsmtFinType1',\n",
    "                   'BsmtFinType2',\n",
    "                   'MasVnrType']\n",
    "\n",
    "for i in missing_val_col:\n",
    "    all_data_df[i] = all_data_df[i].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the following features the null values are there for a purpose, so we replace them with \"0\"\n",
    "missing_val_col2 = ['BsmtFinSF1',\n",
    "                    'BsmtFinSF2',\n",
    "                    'BsmtUnfSF',\n",
    "                    'TotalBsmtSF',\n",
    "                    'BsmtFullBath', \n",
    "                    'BsmtHalfBath', \n",
    "                    'GarageYrBlt',\n",
    "                    'GarageArea',\n",
    "                    'GarageCars',\n",
    "                    'MasVnrArea']\n",
    "\n",
    "for i in missing_val_col2:\n",
    "    all_data_df[i] = all_data_df[i].fillna(0)\n",
    "    \n",
    "## Replaced all missing values in LotFrontage by imputing the median value of each neighborhood. \n",
    "all_data_df['LotFrontage'] = all_data_df.groupby('Neighborhood')['LotFrontage'].transform( lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zoning class are given in numerical; therefore converted to categorical variables. \n",
    "all_data_df['MSSubClass'] = all_data_df['MSSubClass'].astype(str)\n",
    "all_data_df['MSZoning'] = all_data_df.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "## Important years and months that should be categorical variables not numerical. \n",
    "# all_data['YearBuilt'] = all_data['YearBuilt'].astype(str)\n",
    "# all_data['YearRemodAdd'] = all_data['YearRemodAdd'].astype(str)\n",
    "# all_data['GarageYrBlt'] = all_data['GarageYrBlt'].astype(str)\n",
    "all_data_df['YrSold'] = all_data_df['YrSold'].astype(str)\n",
    "all_data_df['MoSold'] = all_data_df['MoSold'].astype(str)\n",
    "\n",
    "all_data_df['Functional'] = all_data_df['Functional'].fillna('Typ') \n",
    "all_data_df['Utilities'] = all_data_df['Utilities'].fillna('AllPub') \n",
    "all_data_df['Exterior1st'] = all_data_df['Exterior1st'].fillna(all_data_df['Exterior1st'].mode()[0]) \n",
    "all_data_df['Exterior2nd'] = all_data_df['Exterior2nd'].fillna(all_data_df['Exterior2nd'].mode()[0])\n",
    "all_data_df['KitchenQual'] = all_data_df['KitchenQual'].fillna(\"TA\") \n",
    "all_data_df['SaleType'] = all_data_df['SaleType'].fillna(all_data_df['SaleType'].mode()[0])\n",
    "all_data_df['Electrical'] = all_data_df['Electrical'].fillna(\"SBrkr\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values with count and percentage\n",
    "count=all_data_df.isnull().sum().sort_values(ascending=False)[\n",
    "    all_data_df.isnull().sum().sort_values(ascending=False)!=0]\n",
    "percent=round(all_data_df.isnull().sum().sort_values(ascending=False)\n",
    "               /len(all_data_df)*100,2)[round(all_data_df.isnull().sum().sort_values(ascending=False)\n",
    "               /len(all_data_df)*100,2)!=0]\n",
    "missing_value_df=pd.concat([count,percent],axis=1)\n",
    "\n",
    "#View missing df\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixing Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data_df.dtypes[all_data_df.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = all_data_df[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "skewed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "sns.distplot(all_data_df['1stFlrSF']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fixing Skewed features using boxcox transformation. \n",
    "\n",
    "\n",
    "def fixing_skewness(df):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and return fixed skewed dataframe\n",
    "    \"\"\"\n",
    "    ## Import necessary modules \n",
    "    from scipy.stats import skew\n",
    "    from scipy.special import boxcox1p\n",
    "    from scipy.stats import boxcox_normmax\n",
    "    \n",
    "    ## Getting all the data that are not of \"object\" type. \n",
    "    numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "\n",
    "    # Check the skew of all numerical features\n",
    "    skewed_feats = df[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "    high_skew = skewed_feats[abs(skewed_feats) > 0.5]\n",
    "    skewed_features = high_skew.index\n",
    "\n",
    "    for feat in skewed_features:\n",
    "        df[feat] = boxcox1p(df[feat], boxcox_normmax(df[feat] + 1))\n",
    "\n",
    "fixing_skewness(all_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(all_data_df['1stFlrSF']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feture engineering a new feature \"TotalFS\"\n",
    "all_data_df['TotalSF'] = (all_data_df['TotalBsmtSF'] \n",
    "                       + all_data_df['1stFlrSF'] \n",
    "                       + all_data_df['2ndFlrSF'])\n",
    "\n",
    "all_data_df['YrBltAndRemod'] = all_data_df['YearBuilt'] + all_data_df['YearRemodAdd']\n",
    "\n",
    "all_data_df['Total_sqr_footage'] = (all_data_df['BsmtFinSF1'] \n",
    "                                 + all_data_df['BsmtFinSF2'] \n",
    "                                 + all_data_df['1stFlrSF'] \n",
    "                                 + all_data_df['2ndFlrSF']\n",
    "                                )\n",
    "                                 \n",
    "\n",
    "all_data_df['Total_Bathrooms'] = (all_data_df['FullBath'] \n",
    "                               + (0.5 * all_data_df['HalfBath']) \n",
    "                               + all_data_df['BsmtFullBath'] \n",
    "                               + (0.5 * all_data_df['BsmtHalfBath'])\n",
    "                              )\n",
    "                               \n",
    "\n",
    "all_data_df['Total_porch_sf'] = (all_data_df['OpenPorchSF'] \n",
    "                              + all_data_df['3SsnPorch'] \n",
    "                              + all_data_df['EnclosedPorch'] \n",
    "                              + all_data_df['ScreenPorch'] \n",
    "                              + all_data_df['WoodDeckSF']\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df['haspool'] = all_data_df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data_df['has2ndfloor'] = all_data_df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data_df['hasgarage'] = all_data_df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data_df['hasbsmt'] = all_data_df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data_df['hasfireplace'] = all_data_df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = all_data_df.drop(['Utilities', 'Street', 'PoolQC',], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dummy variable \n",
    "final_features = pd.get_dummies(all_data_df).reset_index(drop=True)\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_df.SalePrice\n",
    "X = final_features.iloc[:len(y), :]\n",
    "\n",
    "X_sub = final_features.iloc[len(y):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = X.BsmtUnfSF.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
